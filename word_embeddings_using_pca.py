# -*- coding: utf-8 -*-
"""Word Embeddings Using PCA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j0ZbYgYHgqhBtkWOkOHR040GwsOtraXy
"""

!wget https://nlp.stanford.edu/data/glove.6B.zip

!unzip -q glove.6B.zip

with open('glove.6B.100d.txt') as f:
  lines = f.readlines()

my_dict = dict()
for line in lines:
  splitted_line = line.split()
  word = splitted_line[0]
  vec = np.array([float(i) for i in splitted_line[1:]])
  my_dict[word] = vec


words = []
vecs = []
for word, vec in my_dict.items():
  words.append(word)
  vecs.append(vec)
vecs = np.array(vecs)

print(len(words), vecs.shape)


pca = PCA(2).fit(vecs)

X = pca.transform(vecs)
print(X.shape)
     
chosen_words = ['coffee', 'tea', 'water',
                         'spaghetti', 'borscht', 'hamburger', 'pizza', 'falafel', 'sushi', 'meatballs',
                         'dog', 'horse', 'cat', 'monkey', 'parrot', 'koala', 'lizard',
                         'frog', 'toad', 'monkey', 'ape', 'kangaroo', 'wombat', 'wolf',
                         'france', 'germany', 'hungary', 'luxembourg', 'australia', 'fiji', 'china',
                         'homework', 'assignment', 'problem', 'exam', 'test', 'class',
                         'school', 'college', 'university', 'institute']

chosen_indxs = [words.index(word) for word in chosen_words]
X_chosen = X[chosen_indxs, :]
     

plt.figure(figsize=(12, 12))
plt.plot(X_chosen[:, 0], X_chosen[:, 1], 'bo')
for i in range(len(chosen_words)):
  plt.text(X_chosen[i, 0] + 0.05, X_chosen[i, 1] + 0.05, chosen_words[i])
plt.show()